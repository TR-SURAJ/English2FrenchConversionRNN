{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English to French Conversion using RNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English data\n",
    "english_sentences = helper.load_data('C:\\\\Users\\\\KITS\\\\English2FrenchConversionRNN\\\\small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = helper.load_data('C:\\\\Users\\\\KITS\\\\English2FrenchConversionRNN\\\\small_vocab_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n"
     ]
    }
   ],
   "source": [
    "print(english_sentences[0])\n",
    "print(french_sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "French sample 2:  les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n",
      "\n",
      "English sample 3:  california is usually quiet during march , and it is usually hot in june .\n",
      "French sample 3:  california est gÃ©nÃ©ralement calme en mars , et il est gÃ©nÃ©ralement chaud en juin .\n",
      "\n",
      "English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n",
      "French sample 4:  les Ã©tats-unis est parfois lÃ©gÃ¨re en juin , et il fait froid en septembre .\n",
      "\n",
      "English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n",
      "French sample 5:  votre moins aimÃ© fruit est le raisin , mais mon moins aimÃ© est la pomme .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(5):\n",
    "    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab: 227\n",
      "French Vocab: 355\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('English Vocab:',len(english_words_counter))\n",
    "print('French Vocab:',len(french_words_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Sample output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "\n",
    "text_tokenized,text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "\n",
    "for sample_i,(sent,token_sent) in enumerate(zip(text_sentences,text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    return pad_sequences(x, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6 1 7 8]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]\n",
      "  [4]\n",
      "  [5]\n",
      "  [6]\n",
      "  [1]\n",
      "  [7]\n",
      "  [8]]]\n"
     ]
    }
   ],
   "source": [
    "text_sentences = ['The quick brown fox jumps over the lazy dog .']\n",
    "text_tokenized,text_tokenizer = tokenize(text_sentences)\n",
    "preprocess_eng = pad(text_tokenized)\n",
    "print(preprocess_eng)\n",
    "print(type(preprocess_eng))\n",
    "preprocess_eng = preprocess_eng.reshape(*preprocess_eng.shape,1)\n",
    "print(preprocess_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 345\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "    \n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    #Expanding dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    \n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
    "\n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index) \n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 23,  1,  8, 67,  4, 39,  7,  3,  1, 55,  2, 44,  0,  0],\n",
       "       [ 5, 20, 21,  1,  9, 62,  4, 43,  7,  3,  1,  9, 51,  2, 45],\n",
       "       [22,  1,  9, 67,  4, 38,  7,  3,  1,  9, 68,  2, 34,  0,  0],\n",
       "       [ 5, 20, 21,  1,  8, 64,  4, 34,  7,  3,  1, 57,  2, 42,  0],\n",
       "       [29, 12, 16, 13,  1,  5, 82,  6, 30, 12, 16,  1,  5, 83,  0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_english_sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 35],\n",
       "        [ 34],\n",
       "        [  1],\n",
       "        [  8],\n",
       "        [ 67],\n",
       "        [ 37],\n",
       "        [ 11],\n",
       "        [ 24],\n",
       "        [  6],\n",
       "        [  3],\n",
       "        [  1],\n",
       "        [112],\n",
       "        [  2],\n",
       "        [ 50],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  4],\n",
       "        [ 32],\n",
       "        [ 31],\n",
       "        [  1],\n",
       "        [ 12],\n",
       "        [ 19],\n",
       "        [  2],\n",
       "        [ 49],\n",
       "        [  6],\n",
       "        [  3],\n",
       "        [ 95],\n",
       "        [ 69],\n",
       "        [  2],\n",
       "        [ 51],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[101],\n",
       "        [  1],\n",
       "        [ 12],\n",
       "        [ 67],\n",
       "        [  2],\n",
       "        [ 45],\n",
       "        [  6],\n",
       "        [  3],\n",
       "        [  1],\n",
       "        [ 12],\n",
       "        [ 21],\n",
       "        [  2],\n",
       "        [ 41],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  4],\n",
       "        [ 32],\n",
       "        [ 31],\n",
       "        [  1],\n",
       "        [  8],\n",
       "        [269],\n",
       "        [  2],\n",
       "        [ 41],\n",
       "        [  6],\n",
       "        [  3],\n",
       "        [103],\n",
       "        [ 19],\n",
       "        [  2],\n",
       "        [ 48],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[ 40],\n",
       "        [ 13],\n",
       "        [ 14],\n",
       "        [ 16],\n",
       "        [  1],\n",
       "        [ 10],\n",
       "        [ 82],\n",
       "        [  5],\n",
       "        [ 39],\n",
       "        [ 13],\n",
       "        [ 14],\n",
       "        [  1],\n",
       "        [  7],\n",
       "        [ 83],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_french_sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1 : Simple RNN\n",
    "- Model 2 : RNN with Embedding Model\n",
    "- Model 3 : Bidirectional RNN\n",
    "- Model 4 : Encoder-Decoder RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDs to Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict the french translaion of english context. For english context we obtain the probabilites of the respective french translation. The french translation having highest probability predicted by the model will be our corresponding french prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_model(input_shape, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
    "    model.add(GRU(256, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_french_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 23  1  8 67  4 39  7  3  1 55  2 44  0  0  0  0  0  0  0  0]\n",
      "[17 23  1  8 67  4 39  7  3  1 55  2 44  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "print(tmp_x[0])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
    "print(tmp_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 23,  1, ...,  0,  0,  0],\n",
       "       [ 5, 20, 21, ...,  0,  0,  0],\n",
       "       [22,  1,  9, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [24,  1, 10, ...,  0,  0,  0],\n",
       "       [ 5, 84,  1, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 21)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(english_tokenizer.word_index)+1\n",
    "french_vocab_size = len(french_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn_model = embed_model(tmp_x.shape,english_vocab_size,french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 256)           51200     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 21, 256)           394752    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 21, 1024)          263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 21, 346)           354650    \n",
      "=================================================================\n",
      "Total params: 1,063,770\n",
      "Trainable params: 1,063,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "108/108 [==============================] - 250s 2s/step - loss: 1.3453 - accuracy: 0.6841 - val_loss: 0.4709 - val_accuracy: 0.8489\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 256s 2s/step - loss: 0.4042 - accuracy: 0.8684 - val_loss: 0.2980 - val_accuracy: 0.8995\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 248s 2s/step - loss: 0.2869 - accuracy: 0.9045 - val_loss: 0.2392 - val_accuracy: 0.9190\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 247s 2s/step - loss: 0.2420 - accuracy: 0.9182 - val_loss: 0.2150 - val_accuracy: 0.9261\n",
      "Epoch 5/20\n",
      "108/108 [==============================] - 255s 2s/step - loss: 0.2171 - accuracy: 0.9255 - val_loss: 0.2042 - val_accuracy: 0.9302\n",
      "Epoch 6/20\n",
      "108/108 [==============================] - 254s 2s/step - loss: 0.2031 - accuracy: 0.9294 - val_loss: 0.1929 - val_accuracy: 0.9326\n",
      "Epoch 7/20\n",
      "108/108 [==============================] - 251s 2s/step - loss: 0.1949 - accuracy: 0.9317 - val_loss: 0.1872 - val_accuracy: 0.9343\n",
      "Epoch 8/20\n",
      "108/108 [==============================] - 263s 2s/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.1841 - val_accuracy: 0.9354\n",
      "Epoch 9/20\n",
      "108/108 [==============================] - 275s 3s/step - loss: 0.1828 - accuracy: 0.9351 - val_loss: 0.1821 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "108/108 [==============================] - 247s 2s/step - loss: 0.1784 - accuracy: 0.9361 - val_loss: 0.1797 - val_accuracy: 0.9369\n",
      "Epoch 11/20\n",
      "108/108 [==============================] - 253s 2s/step - loss: 0.1775 - accuracy: 0.9364 - val_loss: 0.1803 - val_accuracy: 0.9364\n",
      "Epoch 12/20\n",
      "108/108 [==============================] - 251s 2s/step - loss: 0.1738 - accuracy: 0.9372 - val_loss: 0.1775 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "108/108 [==============================] - 258s 2s/step - loss: 0.1701 - accuracy: 0.9382 - val_loss: 0.1764 - val_accuracy: 0.9386\n",
      "Epoch 14/20\n",
      "108/108 [==============================] - 272s 3s/step - loss: 0.1692 - accuracy: 0.9383 - val_loss: 0.1766 - val_accuracy: 0.9383\n",
      "Epoch 15/20\n",
      "108/108 [==============================] - 250s 2s/step - loss: 0.1677 - accuracy: 0.9387 - val_loss: 0.1821 - val_accuracy: 0.9373\n",
      "Epoch 16/20\n",
      "108/108 [==============================] - 259s 2s/step - loss: 0.1700 - accuracy: 0.9381 - val_loss: 0.1793 - val_accuracy: 0.9382\n",
      "Epoch 17/20\n",
      "108/108 [==============================] - 259s 2s/step - loss: 0.1660 - accuracy: 0.9392 - val_loss: 0.1801 - val_accuracy: 0.9381\n",
      "Epoch 18/20\n",
      "108/108 [==============================] - 263s 2s/step - loss: 0.1631 - accuracy: 0.9399 - val_loss: 0.1815 - val_accuracy: 0.9376\n",
      "Epoch 19/20\n",
      "108/108 [==============================] - 296s 3s/step - loss: 0.1636 - accuracy: 0.9399 - val_loss: 0.1799 - val_accuracy: 0.9382\n",
      "Epoch 20/20\n",
      "108/108 [==============================] - 301s 3s/step - loss: 0.1681 - accuracy: 0.9387 - val_loss: 0.1779 - val_accuracy: 0.9384\n"
     ]
    }
   ],
   "source": [
    "history = simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn_model.save('simple_rnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47085702419281006, 0.2980496883392334, 0.23919250071048737, 0.21500824391841888, 0.20417258143424988, 0.1929040253162384, 0.1871962994337082, 0.18409694731235504, 0.18211981654167175, 0.17968323826789856, 0.18032242357730865, 0.1775401085615158, 0.17643485963344574, 0.17655494809150696, 0.18213587999343872, 0.17927062511444092, 0.18006785213947296, 0.18151937425136566, 0.17988371849060059, 0.17791879177093506]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1,21)\n",
    "plt.plot(epochs,history.history['loss'],color = 'blue')\n",
    "plt.plot(epochs,history.history['val_loss'],color = 'orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 23,  1,  8, 67,  4, 39,  7,  3,  1, 55,  2, 44,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21, 346)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.predict(tmp_x[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8925592e-14, 7.6203014e-13, 8.4322063e-12, ..., 1.4884486e-17,\n",
       "        8.2731180e-20, 1.0723879e-17],\n",
       "       [1.4881109e-10, 6.9524351e-09, 5.4341729e-11, ..., 7.5713344e-17,\n",
       "        5.0944681e-18, 2.4591777e-17],\n",
       "       [3.4811737e-07, 9.8078030e-01, 1.5126050e-09, ..., 1.9428909e-12,\n",
       "        1.1860322e-10, 7.5163297e-13],\n",
       "       ...,\n",
       "       [1.0000000e+00, 7.6368651e-12, 6.0894095e-11, ..., 1.5982250e-25,\n",
       "        7.0054264e-24, 1.3154517e-25],\n",
       "       [1.0000000e+00, 2.3038233e-11, 2.7966174e-10, ..., 1.8668046e-25,\n",
       "        7.3870497e-24, 1.8331991e-25],\n",
       "       [1.0000000e+00, 3.6015649e-11, 5.3541595e-11, ..., 5.2763011e-26,\n",
       "        1.8804210e-24, 4.8330959e-26]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.predict(tmp_x[:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.89255924e-14, 7.62030142e-13, 8.43220632e-12, 7.75400579e-08,\n",
       "       1.54215104e-14, 2.22170815e-08, 1.24172876e-08, 1.70237979e-09,\n",
       "       2.29971410e-18, 1.05329330e-11, 1.90893008e-08, 1.07144545e-13,\n",
       "       5.92844236e-16, 4.92279074e-15, 8.65869339e-18, 1.79622463e-12,\n",
       "       1.79209119e-19, 1.64813268e-19, 3.92241809e-19, 1.35338381e-23,\n",
       "       2.26111122e-12, 1.62339262e-18, 2.52113406e-08, 2.26382609e-19,\n",
       "       1.58535702e-11, 1.32894943e-16, 1.99650084e-12, 8.54265636e-09,\n",
       "       3.10122287e-17, 1.12546993e-10, 1.54831279e-19, 1.08269743e-16,\n",
       "       7.33187122e-12, 9.05741988e-19, 1.02173246e-07, 9.99999762e-01,\n",
       "       1.81187300e-13, 2.90591646e-16, 1.72811035e-20, 1.45748603e-14,\n",
       "       3.01090227e-18, 4.78509808e-21, 1.51043779e-14, 5.80404512e-17,\n",
       "       2.09466450e-18, 8.89756206e-19, 3.07996956e-15, 1.09460360e-16,\n",
       "       5.79189409e-20, 5.21254989e-23, 6.56068575e-16, 6.89494983e-16,\n",
       "       5.23583986e-18, 2.01929245e-15, 2.40765621e-16, 1.02100850e-13,\n",
       "       3.31514669e-14, 9.78068415e-17, 3.13043055e-22, 1.42588997e-17,\n",
       "       2.32048047e-14, 2.34246704e-13, 6.27573297e-12, 4.04284033e-19,\n",
       "       1.64238365e-08, 4.42955011e-19, 2.19606275e-16, 1.46993674e-15,\n",
       "       2.73185622e-16, 2.51255465e-20, 5.84336664e-17, 9.82903355e-27,\n",
       "       2.70310346e-21, 7.01791348e-17, 3.68258541e-23, 1.91189470e-21,\n",
       "       3.77202146e-20, 6.22577682e-20, 8.69822567e-17, 1.50591241e-11,\n",
       "       5.10113205e-16, 5.74226706e-26, 3.89550111e-20, 4.61831077e-15,\n",
       "       1.93351029e-20, 8.46434796e-17, 1.81190795e-20, 3.01093510e-19,\n",
       "       4.26634113e-21, 1.35086813e-21, 1.11557377e-19, 6.46904715e-19,\n",
       "       1.66752272e-11, 1.37319963e-20, 3.02254424e-13, 6.05355329e-19,\n",
       "       3.93959418e-16, 1.53637682e-13, 1.52908055e-16, 8.77774298e-09,\n",
       "       1.95203922e-11, 2.26185841e-11, 2.05352214e-19, 3.26727812e-20,\n",
       "       2.23165523e-19, 4.94099729e-17, 3.64503948e-11, 7.72139297e-11,\n",
       "       1.92293780e-15, 1.58868919e-23, 1.26210884e-15, 6.46794359e-17,\n",
       "       5.56605283e-11, 3.73419605e-20, 1.86907573e-19, 1.15931722e-14,\n",
       "       1.62364306e-11, 9.54536731e-18, 1.17969842e-10, 2.21638418e-19,\n",
       "       5.75282374e-15, 1.05698702e-17, 3.69141046e-12, 3.03722688e-18,\n",
       "       7.29848565e-15, 3.70224855e-23, 5.83349158e-20, 4.91088324e-14,\n",
       "       2.21558774e-13, 4.57401983e-09, 1.65876251e-13, 9.29348504e-13,\n",
       "       1.17405729e-14, 3.33257239e-19, 9.13399199e-20, 8.27680413e-14,\n",
       "       5.39401857e-12, 3.09296861e-22, 1.18762507e-21, 8.97172355e-27,\n",
       "       5.65927725e-28, 1.26228802e-21, 1.41037550e-16, 2.83501447e-19,\n",
       "       2.96791398e-16, 9.63628819e-17, 6.20246694e-15, 1.91212610e-08,\n",
       "       1.26594461e-19, 8.70742127e-17, 5.59938784e-20, 4.28776119e-22,\n",
       "       1.33210663e-12, 1.07729883e-19, 4.39032155e-26, 7.00781728e-20,\n",
       "       1.21238077e-20, 1.27668288e-17, 7.10260908e-19, 4.71026612e-28,\n",
       "       1.72153700e-13, 4.39121467e-16, 1.15661360e-22, 3.12743289e-08,\n",
       "       2.67530410e-13, 2.10101533e-21, 4.12470913e-23, 2.15683946e-19,\n",
       "       1.05868431e-20, 4.75886894e-20, 2.47107293e-13, 2.15629985e-16,\n",
       "       1.34035628e-20, 1.71019581e-18, 2.36040278e-24, 4.12896605e-20,\n",
       "       6.61136524e-22, 7.64586466e-21, 1.08501342e-15, 2.65932105e-19,\n",
       "       1.35265127e-15, 1.54456758e-18, 1.03071885e-18, 5.04677419e-19,\n",
       "       1.29098619e-20, 3.74481331e-18, 6.02937296e-13, 1.06346982e-18,\n",
       "       2.09010091e-16, 9.12380282e-17, 8.35537174e-24, 6.80872241e-16,\n",
       "       1.75572963e-16, 9.28069344e-21, 3.04861896e-15, 8.68127281e-20,\n",
       "       8.96360458e-22, 1.21944678e-17, 1.75205966e-20, 7.11590844e-16,\n",
       "       1.07984511e-20, 2.85052353e-18, 1.41557152e-16, 1.24192192e-21,\n",
       "       1.09237399e-20, 2.66127081e-18, 1.85327167e-19, 8.80409501e-14,\n",
       "       4.87854386e-14, 9.40289354e-20, 2.31022612e-14, 1.34156790e-21,\n",
       "       1.90506725e-12, 4.04417284e-16, 1.55111651e-17, 7.08257134e-16,\n",
       "       3.41402157e-20, 4.02380794e-19, 9.77125942e-15, 1.38442983e-19,\n",
       "       3.00636028e-16, 3.55671294e-15, 3.96787877e-21, 3.52178996e-20,\n",
       "       6.48943818e-19, 4.95524989e-24, 7.93216206e-24, 1.13354887e-25,\n",
       "       1.94097369e-13, 8.89367336e-16, 1.06182745e-19, 7.36393797e-27,\n",
       "       1.14027806e-13, 2.62873010e-19, 5.89242978e-18, 4.37695365e-14,\n",
       "       4.13718235e-19, 3.01071843e-18, 2.45025906e-16, 2.13755940e-18,\n",
       "       2.41955851e-18, 1.26501987e-23, 8.00005364e-23, 2.09978950e-21,\n",
       "       5.93557935e-28, 1.50284550e-14, 4.65738864e-24, 1.15384840e-18,\n",
       "       9.48025690e-20, 1.54667339e-17, 1.24377047e-14, 1.73737131e-12,\n",
       "       2.30860286e-16, 3.12895625e-18, 3.47298331e-15, 8.52702986e-16,\n",
       "       1.54921963e-23, 7.33180603e-22, 7.29714702e-23, 1.40850166e-20,\n",
       "       3.50392906e-19, 1.16731095e-19, 3.53628719e-21, 2.15610181e-24,\n",
       "       5.29652535e-19, 1.53686213e-11, 3.47010415e-18, 5.95015188e-22,\n",
       "       2.14720735e-14, 1.23059761e-23, 7.52225383e-19, 2.16069461e-18,\n",
       "       1.23563402e-18, 8.86585879e-17, 4.17228366e-21, 9.20186531e-22,\n",
       "       5.88935101e-18, 8.92867687e-18, 6.60794266e-20, 5.22543887e-20,\n",
       "       9.24262698e-17, 4.00490900e-20, 3.87276334e-17, 1.53692262e-16,\n",
       "       5.05841301e-20, 5.65011353e-19, 3.24089390e-16, 1.15748780e-14,\n",
       "       1.09670709e-14, 5.48324633e-24, 2.48929930e-17, 1.60707968e-22,\n",
       "       6.66519465e-24, 1.67351410e-17, 4.50499229e-18, 1.46648194e-10,\n",
       "       8.86222697e-20, 1.10112743e-18, 1.88833439e-17, 2.13703328e-22,\n",
       "       1.51537298e-13, 2.45228174e-21, 5.53378483e-16, 2.89349300e-17,\n",
       "       6.72499292e-21, 2.27118991e-24, 8.10074953e-23, 2.22726438e-21,\n",
       "       1.17538196e-17, 1.51582128e-24, 4.21075580e-20, 3.62850551e-17,\n",
       "       1.78826018e-19, 1.58149075e-19, 1.94836703e-12, 3.90469946e-18,\n",
       "       4.99835315e-21, 5.71056673e-20, 4.19782916e-20, 9.32195164e-15,\n",
       "       1.83774846e-19, 2.10691774e-18, 1.37175149e-17, 3.35176190e-18,\n",
       "       1.09182150e-17, 6.82605468e-20, 3.13030250e-20, 2.14269541e-17,\n",
       "       1.94148802e-17, 3.45827541e-19, 1.39442749e-17, 2.34352593e-17,\n",
       "       3.99714434e-18, 4.43331779e-20, 1.34606574e-18, 1.07005408e-18,\n",
       "       2.73746705e-17, 2.19661468e-17, 2.35222921e-19, 1.04567005e-16,\n",
       "       3.84034788e-20, 4.30954456e-19, 6.73969351e-18, 1.48844865e-17,\n",
       "       8.27311798e-20, 1.07238788e-17], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rnn_model.predict(tmp_x[:1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "['new jersey is sometimes quiet during autumn , and it is snowy in april .']\n",
      "-----------------------------------\n",
      "Actual French\n",
      "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\"]\n",
      "-----------------------------------\n",
      "Predicted French\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print('English')\n",
    "print(english_sentences[:1])\n",
    "print('-----------------------------------')\n",
    "print('Actual French')\n",
    "print(french_sentences[:1])\n",
    "print('-----------------------------------')\n",
    "print('Predicted French')\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('est', 1), ('en', 2), ('il', 3), ('les', 4), ('mais', 5), ('et', 6), ('la', 7), ('parfois', 8), ('jamais', 9), ('le', 10), (\"l'\", 11), ('gã©nã©ralement', 12), ('moins', 13), ('aimã©', 14), ('au', 15), ('fruit', 16), ('prã©fã©rã©', 17), ('agrã©able', 18), ('froid', 19), ('son', 20), ('chaud', 21), ('de', 22), ('plus', 23), ('automne', 24), ('mois', 25), ('ã\\xa0', 26), ('elle', 27), ('citrons', 28), ('paris', 29), ('inde', 30), ('unis', 31), ('ã©tats', 32), ('france', 33), ('jersey', 34), ('new', 35), ('chine', 36), ('pendant', 37), ('pamplemousse', 38), ('mon', 39), ('votre', 40), ('juin', 41), ('printemps', 42), ('janvier', 43), ('hiver', 44), ('mars', 45), ('ã©tã©', 46), ('mai', 47), ('septembre', 48), ('juillet', 49), ('avril', 50), ('novembre', 51), ('dã©cembre', 52), ('fã©vrier', 53), ('octobre', 54), ('aime', 55), ('aoã»t', 56), ('merveilleux', 57), ('relaxant', 58), ('doux', 59), ('humide', 60), ('notre', 61), ('californie', 62), ('sec', 63), ('leur', 64), ('occupã©', 65), ('pluvieux', 66), ('calme', 67), ('beau', 68), ('habituellement', 69), ('pommes', 70), ('pãªches', 71), ('oranges', 72), ('poires', 73), ('fraises', 74), ('bananes', 75), ('verts', 76), ('raisins', 77), ('mangues', 78), (\"d'\", 79), ('mangue', 80), ('gel', 81), ('raisin', 82), ('pomme', 83), (\"l'orange\", 84), ('citron', 85), ('chaux', 86), ('banane', 87), ('poire', 88), ('fraise', 89), ('pãªche', 90), ('pas', 91), ('enneigã©e', 92), ('favori', 93), ('dã©teste', 94), ('gã¨le', 95), ('fruits', 96), ('voiture', 97), (\"l'automne\", 98), ('ils', 99), (\"n'aime\", 100), ('california', 101), ('neige', 102), ('fait', 103), ('belle', 104), ('ne', 105), ('vous', 106), ('nous', 107), ('des', 108), ('animal', 109), ('camion', 110), ('cours', 111), ('neigeux', 112), ('conduit', 113), ('prochain', 114), ('ce', 115), ('je', 116), ('tranquille', 117), ('a', 118), ('cher', 119), ('une', 120), ('cette', 121), ('ã©tait', 122), ('aller', 123), ('aiment', 124), ('chaude', 125), ('aimons', 126), (\"n'aiment\", 127), (\"n'aimez\", 128), ('leurs', 129), ('aimez', 130), ('sont', 131), ('dã©testons', 132), ('jaune', 133), ('rouge', 134), (\"j'aime\", 135), ('visiter', 136), ('sã¨che', 137), ('occupã©e', 138), ('frisquet', 139), ('prã©fã©rã©e', 140), ('animaux', 141), ('dernier', 142), ('aimait', 143), ('un', 144), ('conduisait', 145), ('que', 146), ('nouvelle', 147), ('vieille', 148), ('vu', 149), ('verte', 150), ('petite', 151), ('nos', 152), ('noire', 153), ('brillant', 154), ('blanche', 155), ('redoutã©', 156), ('pleut', 157), (\"n'aimait\", 158), ('pamplemousses', 159), ('pense', 160), ('entre', 161), ('bleue', 162), ('nouveau', 163), ('traduire', 164), ('rouillã©e', 165), ('bleu', 166), ('se', 167), ('grande', 168), ('rouillã©', 169), ('ses', 170), (\"qu'il\", 171), ('blanc', 172), ('aux', 173), ('brillante', 174), ('prã©fã©rã©s', 175), ('noir', 176), ('pluies', 177), ('envisage', 178), ('ã©taient', 179), ('va', 180), ('rendre', 181), ('vert', 182), ('vieux', 183), ('petit', 184), ('espagnol', 185), ('portugais', 186), ('chinois', 187), ('anglais', 188), ('franã§ais', 189), ('glaciales', 190), ('mes', 191), ('cet', 192), ('automobile', 193), ('traduction', 194), ('mouillã©', 195), ('difficile', 196), ('amusant', 197), ('facile', 198), ('comme', 199), ('gros', 200), ('souris', 201), ('pourrait', 202), ('voulait', 203), ('veut', 204), ('pourquoi', 205), ('aimã©s', 206), ('prã©vois', 207), ('prã©voyons', 208), ('vos', 209), ('intention', 210), ('clã©mentes', 211), ('ont', 212), ('chat', 213), ('requin', 214), ('cheval', 215), ('chien', 216), ('singe', 217), ('lion', 218), ('ours', 219), ('lapin', 220), ('serpent', 221), ('redoutã©s', 222), ('allã©', 223), ('grosse', 224), ('pluie', 225), ('trop', 226), ('monde', 227), ('maillot', 228), ('vont', 229), ('volant', 230), ('avez', 231), ('i', 232), ('allã©s', 233), ('allã©e', 234), ('quand', 235), ('oiseau', 236), ('ã©lã©phant', 237), ('pourraient', 238), ('voulaient', 239), ('veulent', 240), ('dã©tendre', 241), ('aimã©e', 242), ('magnifique', 243), (\"l'automobile\", 244), (\"n'aimons\", 245), ('gelã©', 246), ('dã©testait', 247), ('grand', 248), ('bien', 249), ('vers', 250), ('prã©voient', 251), ('prã©voit', 252), ('lui', 253), ('visite', 254), ('comment', 255), ('ã©lã©phants', 256), ('chevaux', 257), ('chiens', 258), (\"l'ã©lã©phant\", 259), (\"l'oiseau\", 260), ('requins', 261), (\"l'ours\", 262), ('serpents', 263), ('chats', 264), ('lapins', 265), ('singes', 266), ('oiseaux', 267), ('lions', 268), ('lã©gã¨re', 269), ('cã©page', 270), ('pensez', 271), ('ã‰tats', 272), ('tour', 273), ('eiffel', 274), (\"l'ã©picerie\", 275), ('terrain', 276), ('football', 277), ('lac', 278), (\"l'ã©cole\", 279), (\"l'animal\", 280), (\"n'est\", 281), ('allons', 282), ('allez', 283), ('peu', 284), ('pousse', 285), ('du', 286), ('temps', 287), ('at', 288), ('rouille', 289), ('sur', 290), (\"qu'elle\", 291), ('petites', 292), ('derniã¨re', 293), ('ãªtes', 294), ('vais', 295), ('voudrait', 296), ('proches', 297), ('frais', 298), ('manguiers', 299), ('avons', 300), ('t', 301), ('porcelaine', 302), ('dã©testez', 303), (\"c'est\", 304), ('grandes', 305), ('prã©fã©rã©es', 306), ('douce', 307), ('durant', 308), ('congã©lation', 309), ('plaã®t', 310), ('oã¹', 311), ('dans', 312), ('voulez', 313), ('aimeraient', 314), (\"n'a\", 315), ('petits', 316), ('grands', 317), ('limes', 318), ('envisagent', 319), ('grosses', 320), ('bã©nigne', 321), ('mouillã©e', 322), ('enneigã©', 323), ('moindres', 324), ('conduite', 325), ('gelã©s', 326), ('tout', 327), ('etats', 328), (\"n'ãªtes\", 329), ('vit', 330), ('ressort', 331), ('dã©tend', 332), ('redoutã©e', 333), ('tu', 334), ('qui', 335), ('traduis', 336), ('apprã©ciã©', 337), ('allions', 338), ('trouvã©', 339), ('as', 340), ('faire', 341), ('favoris', 342), ('souvent', 343), ('es', 344), ('moteur', 345)])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_tokenizer.word_index.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fr_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(french_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowCPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
